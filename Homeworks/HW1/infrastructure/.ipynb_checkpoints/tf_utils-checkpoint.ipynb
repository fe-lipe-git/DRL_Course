{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Flatten, Conv2D\n",
    "from tensorflow.keras import Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import altair as alt\n",
    "from vega_datasets import data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mlp(input_, output_size, scope, n_layers, size, activation=tf.tanh, output_activation=None):\n",
    "    \n",
    "    \"\"\"\n",
    "        Builds a feedforward neural network\n",
    "        arguments:\n",
    "            input_placeholder: placeholder variable for the state (batch_size, input_size)\n",
    "            scope: variable scope of the network\n",
    "            n_layers: number of hidden layers\n",
    "            size: dimension of each hidden layer\n",
    "            activation: activation of each hidden layer\n",
    "            output_size: size of the output layer\n",
    "            output_activation: activation of the output layer\n",
    "        returns:\n",
    "            output_placeholder: the result of a forward pass through the hidden layers + the output layer\n",
    "    \"\"\"\n",
    "    output_placeholder = input_placeholder\n",
    "    with tf.variable_scope(scope):\n",
    "        for _ in range(n_layers):\n",
    "            output_placeholder = tf.layers.dense(output_placeholder, size, activation)  # Zohar\n",
    "        output_placeholder = tf.layers.dense(output_placeholder, output_size, output_activation)  # Zohar\n",
    "    return output_placeholder\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class build_mlp(Model):\n",
    "    \n",
    "    def __init__(self, n_layers, size, activation = tf.tanh, output_activation=None):\n",
    "        \n",
    "        super(build_mlp,self).__init__()\n",
    "        self.layers = [Dense(size,activation=activation) for _ in range(n_layers-1)]\n",
    "        self.outputLayer = Dense(size, activation=output_activation)\n",
    "        \n",
    "    def call(self,input_data):\n",
    "        \n",
    "        x=input_data\n",
    "        for layer in self.layers:\n",
    "            \n",
    "            x = layer(x)\n",
    "            \n",
    "        return self.outputLayer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 371401286666119507\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 16649773394052431134\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sudo add-apt-repository \"deb [arch=amd64] https://download.docker.com/linux/ubuntu  $(lsb_release -cs)  stable\" "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
